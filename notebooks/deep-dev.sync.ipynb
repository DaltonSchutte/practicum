{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a2f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dalton/projects/practicum/env/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "from string import Template\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from momentfm import MOMENTPipeline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.data import TimeSeries\n",
    "from src.methods.deep import (\n",
    "    DeepStoppingModel,\n",
    "    TimeSeriesDataset,\n",
    "    DLDataset,\n",
    "    collator\n",
    ")\n",
    "from src.eval import (\n",
    "    mean_time_from_event,\n",
    "    classification_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00f85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3141\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd50b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts = TimeSeries.from_csv(\n",
    "    'pandas',\n",
    "    '../data/blood-refrigerator/train.csv'\n",
    ")\n",
    "valid_ts = TimeSeries.from_csv(\n",
    "    'pandas',\n",
    "    '../data/blood-refrigerator/val.csv'\n",
    ")\n",
    "test_ts = TimeSeries.from_csv(\n",
    "    'pandas',\n",
    "    '../data/blood-refrigerator/test.csv'\n",
    ")\n",
    "\n",
    "train_ts.parse_datetime('timestamp')\n",
    "valid_ts.parse_datetime('timestamp')\n",
    "test_ts.parse_datetime('timestamp')\n",
    "\n",
    "train_ts.split_by_day()\n",
    "valid_ts.split_by_day()\n",
    "test_ts.split_by_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d234cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.concat(\n",
    "    train_ts.time_series[k].drop(\n",
    "        columns=['timestamp','PW_0.5h','date','time']\n",
    "    ) for k in train_ts.time_series.keys()\n",
    ")\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    c for c in temp.columns if np.std(temp[c])!=0\n",
    "]\n",
    "LABEL_COL = 'PW_0.5h'\n",
    "\n",
    "temp = None\n",
    "del temp\n",
    "len(FEATURE_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ec8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_windows(df, window={'minutes': 20}):\n",
    "    tf = '%Y-%m-%d %H:%M:%S.%f'\n",
    "    windows = []\n",
    "    window_size = datetime.timedelta(**window)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    for i, row in df.iterrows():\n",
    "        start_t = datetime.datetime.strptime(row['timestamp'], tf)\n",
    "        for j, row2 in df.iloc[i:].iterrows():\n",
    "            end_t = datetime.datetime.strptime(row2['timestamp'], tf)\n",
    "            if end_t - start_t >= window_size:\n",
    "                try:\n",
    "                    label = df['PW_0.5h'].iloc[j+1]\n",
    "                except IndexError:\n",
    "                    label = df['PW_0.5h'].iloc[-1]\n",
    "                except err:\n",
    "                    print(err)\n",
    "                windows.append(\n",
    "                    (df.iloc[i:j+1], label)\n",
    "                )\n",
    "                break\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ac83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': (59266, 59266, 0.011878648803698579),\n",
       " 'valid': (13740, 13740, 0.06091703056768559),\n",
       " 'test': (64791, 64791, 0.009924217869765863)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = '../data/blood-refrigerator/preprocessed'\n",
    "if not os.path.isfile(os.path.join(save_dir, 'X_train.pkl')):\n",
    "    print('Making datasets...')\n",
    "    train_windows = {\n",
    "        dt: get_time_windows(ts) for dt, ts in train_ts.time_series.items()\n",
    "    }\n",
    "\n",
    "    valid_windows = {\n",
    "        dt: get_time_windows(ts) for dt, ts in valid_ts.time_series.items()\n",
    "    }\n",
    "    test_windows = {\n",
    "        dt: get_time_windows(ts) for dt, ts in test_ts.time_series.items()\n",
    "    }\n",
    "\n",
    "    X_train = [\n",
    "        df[FEATURE_COLS].values for pr in train_windows.values() for (df,_) in pr\n",
    "    ]\n",
    "    y_train = [\n",
    "        l for pr in train_windows.values() for (_,l) in pr\n",
    "    ]\n",
    "    X_valid = [\n",
    "        df[FEATURE_COLS].values for pr in valid_windows.values() for (df,_) in pr\n",
    "    ]\n",
    "    y_valid = [\n",
    "        l for pr in valid_windows.values() for (_,l) in pr\n",
    "    ]\n",
    "    X_test = [\n",
    "        df[FEATURE_COLS].values for pr in test_windows.values() for (df,_) in pr\n",
    "    ]\n",
    "    y_test = [\n",
    "        l for pr in test_windows.values() for (_,l) in pr\n",
    "    ]\n",
    "\n",
    "    pickle.dump(X_train, open(os.path.join(save_dir, 'X_train.pkl'), 'wb'))\n",
    "    pickle.dump(y_train, open(os.path.join(save_dir, 'y_train.pkl'), 'wb'))\n",
    "    pickle.dump(X_valid, open(os.path.join(save_dir, 'X_valid.pkl'), 'wb'))\n",
    "    pickle.dump(y_valid, open(os.path.join(save_dir, 'y_valid.pkl'), 'wb'))\n",
    "    pickle.dump(X_test, open(os.path.join(save_dir, 'X_test.pkl'), 'wb'))\n",
    "    pickle.dump(y_test, open(os.path.join(save_dir, 'y_test.pkl'), 'wb'))\n",
    "else:\n",
    "    print('Loading...')\n",
    "    X_train = pickle.load(open(os.path.join(save_dir, 'X_train.pkl'), 'rb'))\n",
    "    y_train = pickle.load(open(os.path.join(save_dir, 'y_train.pkl'), 'rb'))\n",
    "    X_valid = pickle.load(open(os.path.join(save_dir, 'X_valid.pkl'), 'rb'))\n",
    "    y_valid = pickle.load(open(os.path.join(save_dir, 'y_valid.pkl'), 'rb'))\n",
    "    X_test = pickle.load(open(os.path.join(save_dir, 'X_test.pkl'), 'rb'))\n",
    "    y_test = pickle.load(open(os.path.join(save_dir, 'y_test.pkl'), 'rb'))\n",
    "\n",
    "\n",
    "{\n",
    "    'train': (len(X_train), len(y_train), np.mean(y_train)),\n",
    "    'valid': (len(X_valid), len(y_valid), np.mean(y_valid)),\n",
    "    'test': (len(X_test), len(y_test), np.mean(y_test))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e21f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DLDataset(X_train, y_train)\n",
    "valid_ds = DLDataset(X_valid, y_valid)\n",
    "test_ds = DLDataset(X_test, y_test)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    "    drop_last=True\n",
    ")\n",
    "valid_dl = DataLoader(\n",
    "    valid_ds,\n",
    "    collate_fn=collator\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    collate_fn=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d5f2e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 12, 512]),\n",
       " torch.Size([8, 512]),\n",
       " torch.Size([8]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, mask, y in train_dl:\n",
    "    break\n",
    "\n",
    "x.shape, mask.shape, y.shape, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5c6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepStoppingModel(\n",
    "    'transformer',\n",
    "    len(FEATURE_COLS),\n",
    "    device='cuda',\n",
    "    save_dir='../results/deep/transformer.pt',\n",
    "    bsz=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d0b6138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0119, 0.9881], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pw1 = np.mean(train_ds.y)\n",
    "pw0 = 1-pw1\n",
    "pw0,pw1\n",
    "weights = torch.tensor([1/pw0,1/pw1])\n",
    "weights /= weights.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae33c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b5e616ab4547058642142c4ee4e854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cfec898f6746d59e6237cb7be25de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dalton/projects/practicum/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/dalton/projects/practicum/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fee3ae0352a429783c4ecd2ba1f1e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     12903\n",
      "           1       0.00      0.00      0.00       837\n",
      "\n",
      "    accuracy                           0.94     13740\n",
      "   macro avg       0.47      0.50      0.48     13740\n",
      "weighted avg       0.88      0.94      0.91     13740\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a8673af47143839d78f39383dd5e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dalton/projects/practicum/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/dalton/projects/practicum/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Expects tensors in [bsz, in_channels, seqlen]\n",
    "model.train(\n",
    "    5,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    class_weight=weights,\n",
    "    lr=1e-3,\n",
    "    eta_min=1e-6,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
