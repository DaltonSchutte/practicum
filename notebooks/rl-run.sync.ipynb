{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcbcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.data import TimeSeries\n",
    "from src.methods import rl\n",
    "from src.environment import TimeSeriesEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "SEED = 3141\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b2de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dir in os.listdir('../data'):\n",
    "    if dir in ['nitrogen-generator','wrapper-machine']:\n",
    "        continue\n",
    "\n",
    "    print(dir.upper())\n",
    "    # Data loading\n",
    "    data_dir_path = os.path.join('../data', dir)\n",
    "    \n",
    "    X_train = pickle.load(open(os.path.join('../data',dir,'preprocessed/X_train.pkl'), 'rb'))\n",
    "    X_valid = pickle.load(open(os.path.join('../data',dir,'preprocessed/X_valid.pkl'), 'rb'))\n",
    "    X_test = pickle.load(open(os.path.join('../data',dir,'preprocessed/X_test.pkl'), 'rb'))\n",
    "    y_train = pickle.load(open(os.path.join('../data',dir,'preprocessed/y_train.pkl'), 'rb'))\n",
    "    y_valid = pickle.load(open(os.path.join('../data',dir,'preprocessed/y_valid.pkl'), 'rb'))\n",
    "    y_test = pickle.load(open(os.path.join('../data',dir,'preprocessed/y_test.pkl'), 'rb'))\n",
    "    \n",
    "\n",
    "    # Data loading\n",
    "    data_dir_path = os.path.join('../data', dir)\n",
    "    if dir == 'nitrogen-generator':\n",
    "        tf = '%Y-%m-%d %H:%M:%S'\n",
    "    else:\n",
    "        tf = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "    train_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'train.csv')\n",
    "    )\n",
    "    valid_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'val.csv')\n",
    "    )\n",
    "    test_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'test.csv')\n",
    "    )\n",
    "\n",
    "    # Data prep\n",
    "    train_ts.parse_datetime('timestamp', tf)\n",
    "    valid_ts.parse_datetime('timestamp', tf)\n",
    "    test_ts.parse_datetime('timestamp', tf)\n",
    "\n",
    "    train_ts.split_by_day()\n",
    "    valid_ts.split_by_day()\n",
    "    test_ts.split_by_day()\n",
    "\n",
    "    temp = pd.concat(\n",
    "        train_ts.time_series[k].drop(\n",
    "            columns=['timestamp','PW_0.5h','date','time']\n",
    "        ) for k in train_ts.time_series.keys()\n",
    "    )\n",
    "\n",
    "    FEATURE_COLS = [\n",
    "        c for c in temp.columns if np.std(temp[c])!=0\n",
    "    ]\n",
    "    LABEL_COL = 'PW_0.5h'\n",
    "\n",
    "    temp = None\n",
    "    del temp\n",
    "\n",
    "    # Make environments\n",
    "    train_env = TimeSeriesEnv(train_ts, FEATURE_COLS, LABEL_COL, True)\n",
    "    valid_env = TimeSeriesEnv(valid_ts, FEATURE_COLS, LABEL_COL, False)\n",
    "    test_env = TimeSeriesEnv(test_ts, FEATURE_COLS, LABEL_COL, False)\n",
    "\n",
    "    # Model prep\n",
    "    hid_dim = 0\n",
    "    for i in range(10):\n",
    "        if 2**i > len(FEATURE_COLS):\n",
    "            hid_dim = 2**(i+1)\n",
    "            break\n",
    "    print('Features: ', len(FEATURE_COLS))\n",
    "    print('Hidden Dim: ',hid_dim)\n",
    "    alpha_stop = rl.NeuralNetGuidedMCTS(\n",
    "        in_dim=len(FEATURE_COLS),\n",
    "        hid_dim=hid_dim,\n",
    "        save_dir=os.path.join('../results/rl',dir),\n",
    "        n_actions=2,\n",
    "        n_sim=100,\n",
    "        lr=1e-4,\n",
    "        weight_decay=0.01,\n",
    "        gamma=0.999,\n",
    "        bsz=64,\n",
    "        device='cpu'\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    epochs = 100\n",
    "    train_actions, train_rewards = alpha_stop.train(epochs, train_env, valid_env)\n",
    "\n",
    "    # Load and test best model\n",
    "    alpha_stop.net.load_state_dict(\n",
    "        torch.load(\n",
    "            os.path.join('../results/rl',dir,'network.pt')\n",
    "        )\n",
    "    )\n",
    "    alpha_stop.mcts = pickle.load(open(os.path.join('../results/rl',dir,'mcts.pkl'),'rb'))\n",
    "    test_actions, test_rewards = alpha_stop.run(test_env)\n",
    "    \n",
    "    # Save output\n",
    "    pickle.dump(train_actions, open(os.path.join('../results/rl',dir,'train_actions.pkl'), 'wb'))\n",
    "    pickle.dump(train_rewards, open(os.path.join('../results/rl',dir,'train_rewards.pkl'), 'wb'))\n",
    "    pickle.dump(test_actions, open(os.path.join('../results/rl',dir,'test_actions.pkl'), 'wb'))\n",
    "    pickle.dump(test_rewards, open(os.path.join('../results/rl',dir,'test_rewards.pkl'), 'wb'))\n",
    "\n",
    "print(\"<< PROCESS COMPELTE >>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.listdir('../data'):\n",
    "    if dir in ['nitrogen-generator','wrapper-machine']:\n",
    "        continue\n",
    "\n",
    "    print(dir.upper())\n",
    "    # Data loading\n",
    "    data_dir_path = os.path.join('../data', dir)\n",
    "    \n",
    "    X_train = pickle.load(open(os.path.join('../data',dir,'preprocessed/X_train.pkl'), 'rb'))\n",
    "    X_valid = pickle.load(open(os.path.join('../data',dir,'preprocessed/X_valid.pkl'), 'rb'))\n",
    "    X_test = pickle.load(open(os.path.join('../data',dir,'preprocessed/X_test.pkl'), 'rb'))\n",
    "    y_train = pickle.load(open(os.path.join('../data',dir,'preprocessed/y_train.pkl'), 'rb'))\n",
    "    y_valid = pickle.load(open(os.path.join('../data',dir,'preprocessed/y_valid.pkl'), 'rb'))\n",
    "    y_test = pickle.load(open(os.path.join('../data',dir,'preprocessed/y_test.pkl'), 'rb'))\n",
    "    \n",
    "\n",
    "    # Data loading\n",
    "    data_dir_path = os.path.join('../data', dir)\n",
    "    if dir == 'nitrogen-generator':\n",
    "        tf = '%Y-%m-%d %H:%M:%S'\n",
    "    else:\n",
    "        tf = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "    train_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'train.csv')\n",
    "    )\n",
    "    valid_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'val.csv')\n",
    "    )\n",
    "    test_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'test.csv')\n",
    "    )\n",
    "\n",
    "    # Data prep\n",
    "    train_ts.parse_datetime('timestamp', tf)\n",
    "    valid_ts.parse_datetime('timestamp', tf)\n",
    "    test_ts.parse_datetime('timestamp', tf)\n",
    "\n",
    "    train_ts.split_by_day()\n",
    "    valid_ts.split_by_day()\n",
    "    test_ts.split_by_day()\n",
    "\n",
    "    temp = pd.concat(\n",
    "        train_ts.time_series[k].drop(\n",
    "            columns=['timestamp','PW_0.5h','date','time']\n",
    "        ) for k in train_ts.time_series.keys()\n",
    "    )\n",
    "\n",
    "    FEATURE_COLS = [\n",
    "        c for c in temp.columns if np.std(temp[c])!=0\n",
    "    ]\n",
    "    LABEL_COL = 'PW_0.5h'\n",
    "\n",
    "    temp = None\n",
    "    del temp\n",
    "\n",
    "    # Make environments\n",
    "    train_env = TimeSeriesEnv(train_ts, FEATURE_COLS, LABEL_COL, True)\n",
    "    valid_env = TimeSeriesEnv(valid_ts, FEATURE_COLS, LABEL_COL, False)\n",
    "    test_env = TimeSeriesEnv(test_ts, FEATURE_COLS, LABEL_COL, False)\n",
    "\n",
    "    # Model prep\n",
    "    hid_dim = 0\n",
    "    for i in range(10):\n",
    "        if 2**i > len(FEATURE_COLS):\n",
    "            hid_dim = 2**(i+1)\n",
    "            break\n",
    "    print('Features: ', len(FEATURE_COLS))\n",
    "    print('Hidden Dim: ',hid_dim)\n",
    "    ppo = rl.PPOAgent(\n",
    "        in_dim=len(FEATURE_COLS),\n",
    "        hid_dim=hid_dim,\n",
    "        clip=0.2,\n",
    "        update_freq=10,\n",
    "        save_dir=os.path.join('../results/rl',dir),\n",
    "        lr=3e-4,\n",
    "        gamma=0.99,\n",
    "        bsz=64,\n",
    "        device='cuda'\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    epochs = 1000\n",
    "    train_actions, train_rewards = ppo.train(epochs, train_env, valid_env)\n",
    "\n",
    "    # Load and test best model\n",
    "    ppo.policy_net.load_state_dict(\n",
    "        torch.load(\n",
    "            os.path.join('../results/rl',dir,'ppo-policy-network.pt')\n",
    "        )\n",
    "    )\n",
    "    test_actions, test_rewards = ppo.run(test_env)\n",
    "    \n",
    "    # Save output\n",
    "    pickle.dump(train_actions, open(os.path.join('../results/rl',dir,'ppo_train_actions.pkl'), 'wb'))\n",
    "    pickle.dump(train_rewards, open(os.path.join('../results/rl',dir,'ppo_train_rewards.pkl'), 'wb'))\n",
    "    pickle.dump(test_actions, open(os.path.join('../results/rl',dir,'ppo_test_actions.pkl'), 'wb'))\n",
    "    pickle.dump(test_rewards, open(os.path.join('../results/rl',dir,'ppo_test_rewards.pkl'), 'wb'))\n",
    "\n",
    "print(\"<< PROCESS COMPELTE >>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a82700",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(train_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(train_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f0baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6d1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
