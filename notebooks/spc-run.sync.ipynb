{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "303b4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from string import Template\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.data import TimeSeries\n",
    "from src.methods.spc import FControlChart, PatternFunction\n",
    "from src.eval import (\n",
    "    mean_time_from_event,\n",
    "    classification_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129f2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d754e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultTup = namedtuple(\n",
    "    'ResultTup',\n",
    "    ['split_pct','pattern','strict','mean_time_from_event','f1','precision','recall']\n",
    ")\n",
    "\n",
    "def exceeds_n_breaches(values: np.ndarray, ucl, n):\n",
    "    if (values > ucl).sum() >= 5:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def n_sequential_breaches(values: np.ndarray, ucl, n):\n",
    "    if (values > ucl).sum() == n:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197fca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOOD-REFRIGERATOR\n",
      "0.25 4.40494168243589 11.340580214850563 23.327548055804176\n",
      "0.5 4.404351913862327 11.340448361372395 23.33220932530158\n",
      "0.75 4.404161271096154 11.340405734198246 23.33371651971875\n",
      "1.0 4.40406654080088 11.340384551773854 23.334465523566966\n",
      "NITROGEN-GENERATOR\n",
      "0.25 0.4845147249400172 3.356815922958415 11.138793865415558\n",
      "0.5 0.4844635285405625 3.3567510037474375 11.1411852346333\n",
      "0.75 0.48444790482963385 3.356731192699808 11.141915241438458\n",
      "1.0 0.4844396604235086 3.356720738787895 11.142300498403953\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir('../data'):\n",
    "    if dir == 'wrapper-machine':\n",
    "        continue\n",
    "\n",
    "    print(dir.upper())\n",
    "    # Data loading\n",
    "    data_dir_path = os.path.join('../data', dir)\n",
    "    if dir == 'nitrogen-generator':\n",
    "        tf = '%Y-%m-%d %H:%M:%S'\n",
    "    else:\n",
    "        tf = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "    train_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'train.csv')\n",
    "    )\n",
    "    test_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'test.csv')\n",
    "    )\n",
    "\n",
    "    # Data prep\n",
    "    train_ts.parse_datetime('timestamp', tf)\n",
    "    test_ts.parse_datetime('timestamp', tf)\n",
    "\n",
    "    train_ts.split_by_day()\n",
    "    test_ts.split_by_day()\n",
    "\n",
    "    temp = pd.concat(\n",
    "        train_ts.time_series[k].drop(\n",
    "            columns=['timestamp','PW_0.5h','date','time']\n",
    "        ) for k in train_ts.time_series.keys()\n",
    "    )\n",
    "\n",
    "    FEATURE_COLS = [\n",
    "        c for c in temp.columns if np.std(temp[c])!=0\n",
    "    ]\n",
    "    LABEL_COL = 'PW_0.5h'\n",
    "\n",
    "    temp = None\n",
    "    del temp\n",
    "\n",
    "    splits = [0.25,0.5,0.75,1.0]\n",
    "    train_splits = {}\n",
    "    for pct in splits:\n",
    "        n_days = len(train_ts.time_series)\n",
    "        train_days = list(train_ts.time_series.keys())[-int(pct*n_days):]\n",
    "        y = pd.concat([\n",
    "            train_ts.time_series[k]['PW_0.5h'] for k in train_days\n",
    "        ])\n",
    "        X = pd.concat([\n",
    "            train_ts.time_series[k].drop(\n",
    "                columns=['timestamp','PW_0.5h','date','time']\n",
    "            ) for k in train_days\n",
    "        ])\n",
    "\n",
    "        # Drop std=0 variables\n",
    "        X = X[FEATURE_COLS]\n",
    "            \n",
    "        train_splits.update(\n",
    "            {\n",
    "                str(pct):\n",
    "                {\n",
    "                    'X': X.values,\n",
    "                    'y': y.values\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    test_data = {\n",
    "        'X': {dt: x[FEATURE_COLS].values for dt, x in test_ts.time_series.items()},\n",
    "        'y': {dt: x['PW_0.5h'].values for dt, x in test_ts.time_series.items()}\n",
    "    }\n",
    "\n",
    "    charts = {}\n",
    "\n",
    "    for nm, split in train_splits.items():\n",
    "        chart = FControlChart()\n",
    "        chart.determine_parameters(split['X'])\n",
    "        charts.update(\n",
    "            {\n",
    "                nm: chart\n",
    "            }\n",
    "        )\n",
    "        print(nm, chart.lcl, chart.center_line, chart.ucl)\n",
    "\n",
    "    test_matches = {}\n",
    "\n",
    "    for nm, chart in charts.items():\n",
    "        test_matches[nm] = {}\n",
    "\n",
    "        for n in [5,10,20,40,80]:\n",
    "            chart.add_patterns(\n",
    "                {\n",
    "                    f'{n}per{n*2}at0.05': PatternFunction(\n",
    "                        exceeds_n_breaches,\n",
    "                        int(n*2),\n",
    "                        {'ucl': chart.ucl, 'n':n}\n",
    "                    ),\n",
    "                    f'{n}seqAt0.05': PatternFunction(\n",
    "                        exceeds_n_breaches,\n",
    "                        int(n),\n",
    "                        {'ucl': chart.ucl, 'n':n}\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "        for dt, X in test_data['X'].items():\n",
    "            matched = chart.check_patterns(X)\n",
    "            for pattern, res in matched.items():\n",
    "                if not test_matches[nm].get(pattern, False):\n",
    "                    test_matches[nm].update({pattern: {}})\n",
    "                test_matches[nm][pattern].update(\n",
    "                    {\n",
    "                        dt: res\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    test_result_for_out = []\n",
    "\n",
    "    # Non-strict eval\n",
    "    for pct, res in test_matches.items():\n",
    "        for pattern, matches in res.items():  \n",
    "            diffs, mtfe = mean_time_from_event(test_data['y'], matches)\n",
    "            hits, mets = classification_metrics(test_data['y'], matches)\n",
    "\n",
    "            test_result_for_out.append(\n",
    "                ResultTup(\n",
    "                    pct,\n",
    "                    pattern,\n",
    "                    0,\n",
    "                    mtfe,\n",
    "                    mets['f1'],\n",
    "                    mets['precision'],\n",
    "                    mets['recall']\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Strict eval\n",
    "    for pct, res in test_matches.items():\n",
    "        for pattern, matches in res.items():  \n",
    "            diffs, mtfe = mean_time_from_event(test_data['y'], matches, strict=True)\n",
    "            hits, mets = classification_metrics(test_data['y'], matches, strict=True)\n",
    "            ResultTup(\n",
    "                pct,\n",
    "                pattern,\n",
    "                1,\n",
    "                mtfe,\n",
    "                mets['f1'],\n",
    "                mets['precision'],\n",
    "                mets['recall']\n",
    "            )\n",
    "        \n",
    "    test_result_df = pd.DataFrame(test_result_for_out)\n",
    "    test_result_df.to_csv(\n",
    "        os.path.join('../results/spc',dir,'test-results.tsv'),\n",
    "        sep='\\t',\n",
    "        header=True,\n",
    "        index=False\n",
    "    )\n",
    "    pickle.dump(\n",
    "        charts,\n",
    "        open(os.path.join('../results/spc',dir,'charts.pkl'), 'wb')\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
