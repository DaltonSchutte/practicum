{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from string import Template\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.data import TimeSeries\n",
    "from src.methods.spc import FControlChart, PatternFunction\n",
    "from src.eval import (\n",
    "    mean_time_from_event,\n",
    "    classification_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultTup = namedtuple(\n",
    "    'ResultTup',\n",
    "    ['split_pct','pattern','strict','mean_time_from_event','f1','precision','recall']\n",
    ")\n",
    "\n",
    "def exceeds_n_breaches(values: np.ndarray, ucl, n):\n",
    "    if (values > ucl).sum() >= 5:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def n_sequential_breaches(values: np.ndarray, ucl, n):\n",
    "    if (values > ucl).sum() == n:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197fca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.listdir('../data'):\n",
    "    if dir == 'wrapper-machine':\n",
    "        continue\n",
    "\n",
    "    print(dir.upper())\n",
    "    # Data loading\n",
    "    data_dir_path = os.path.join('../data', dir)\n",
    "    if dir == 'nitrogen-generator':\n",
    "        tf = '%Y-%m-%d %H:%M:%S'\n",
    "    else:\n",
    "        tf = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "    train_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'train.csv')\n",
    "    )\n",
    "    test_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'test.csv')\n",
    "    )\n",
    "\n",
    "    # Data prep\n",
    "    train_ts.parse_datetime('timestamp', tf)\n",
    "    test_ts.parse_datetime('timestamp', tf)\n",
    "\n",
    "    train_ts.split_by_day()\n",
    "    test_ts.split_by_day()\n",
    "\n",
    "    temp = pd.concat(\n",
    "        train_ts.time_series[k].drop(\n",
    "            columns=['timestamp','PW_0.5h','date','time']\n",
    "        ) for k in train_ts.time_series.keys()\n",
    "    )\n",
    "\n",
    "    FEATURE_COLS = [\n",
    "        c for c in temp.columns if np.std(temp[c])!=0\n",
    "    ]\n",
    "    LABEL_COL = 'PW_0.5h'\n",
    "\n",
    "    temp = None\n",
    "    del temp\n",
    "\n",
    "    splits = [0.25,0.5,0.75,1.0]\n",
    "    train_splits = {}\n",
    "    for pct in splits:\n",
    "        n_days = len(train_ts.time_series)\n",
    "        train_days = list(train_ts.time_series.keys())[-int(pct*n_days):]\n",
    "        y = pd.concat([\n",
    "            train_ts.time_series[k]['PW_0.5h'] for k in train_days\n",
    "        ])\n",
    "        X = pd.concat([\n",
    "            train_ts.time_series[k].drop(\n",
    "                columns=['timestamp','PW_0.5h','date','time']\n",
    "            ) for k in train_days\n",
    "        ])\n",
    "\n",
    "        # Drop std=0 variables\n",
    "        X = X[FEATURE_COLS]\n",
    "            \n",
    "        train_splits.update(\n",
    "            {\n",
    "                str(pct):\n",
    "                {\n",
    "                    'X': X.values,\n",
    "                    'y': y.values\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    test_data = {\n",
    "        'X': {dt: x[FEATURE_COLS].values for dt, x in test_ts.time_series.items()},\n",
    "        'y': {dt: x['PW_0.5h'].values for dt, x in test_ts.time_series.items()}\n",
    "    }\n",
    "\n",
    "    charts = {}\n",
    "\n",
    "    for nm, split in train_splits.items():\n",
    "        chart = FControlChart()\n",
    "        chart.determine_parameters(split['X'])\n",
    "        charts.update(\n",
    "            {\n",
    "                nm: chart\n",
    "            }\n",
    "        )\n",
    "        print(nm, chart.lcl, chart.center_line, chart.ucl)\n",
    "\n",
    "    test_matches = {}\n",
    "\n",
    "    for nm, chart in charts.items():\n",
    "        test_matches[nm] = {}\n",
    "\n",
    "        for n in [5,10,20,40,80]:\n",
    "            chart.add_patterns(\n",
    "                {\n",
    "                    f'{n}per{n*2}at0.05': PatternFunction(\n",
    "                        exceeds_n_breaches,\n",
    "                        int(n*2),\n",
    "                        {'ucl': chart.ucl, 'n':n}\n",
    "                    ),\n",
    "                    f'{n}seqAt0.05': PatternFunction(\n",
    "                        exceeds_n_breaches,\n",
    "                        int(n),\n",
    "                        {'ucl': chart.ucl, 'n':n}\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "        for dt, X in test_data['X'].items():\n",
    "            matched = chart.check_patterns(X)\n",
    "            for pattern, res in matched.items():\n",
    "                if not test_matches[nm].get(pattern, False):\n",
    "                    test_matches[nm].update({pattern: {}})\n",
    "                test_matches[nm][pattern].update(\n",
    "                    {\n",
    "                        dt: res\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    test_result_for_out = []\n",
    "\n",
    "    # Non-strict eval\n",
    "    for pct, res in test_matches.items():\n",
    "        for pattern, matches in res.items():  \n",
    "            diffs, mtfe = mean_time_from_event(test_data['y'], matches)\n",
    "            hits, mets = classification_metrics(test_data['y'], matches)\n",
    "\n",
    "            test_result_for_out.append(\n",
    "                ResultTup(\n",
    "                    pct,\n",
    "                    pattern,\n",
    "                    0,\n",
    "                    mtfe,\n",
    "                    mets['f1'],\n",
    "                    mets['precision'],\n",
    "                    mets['recall']\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Strict eval\n",
    "    for pct, res in test_matches.items():\n",
    "        for pattern, matches in res.items():  \n",
    "            diffs, mtfe = mean_time_from_event(test_data['y'], matches, strict=True)\n",
    "            hits, mets = classification_metrics(test_data['y'], matches, strict=True)\n",
    "            ResultTup(\n",
    "                pct,\n",
    "                pattern,\n",
    "                1,\n",
    "                mtfe,\n",
    "                mets['f1'],\n",
    "                mets['precision'],\n",
    "                mets['recall']\n",
    "            )\n",
    "        \n",
    "    test_result_df = pd.DataFrame(test_result_for_out)\n",
    "    test_result_df.to_csv(\n",
    "        os.path.join('../results/spc',dir,'test-results.tsv'),\n",
    "        sep='\\t',\n",
    "        header=True,\n",
    "        index=False\n",
    "    )\n",
    "    pickle.dump(\n",
    "        charts,\n",
    "        open(os.path.join('../results/spc',dir,'charts.pkl'), 'wb')\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
