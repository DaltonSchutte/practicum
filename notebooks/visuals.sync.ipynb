{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d366e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from string import Template\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.data import TimeSeries\n",
    "from src.methods.spc import FControlChart, PatternFunction\n",
    "from src.eval import (\n",
    "    mean_time_from_event,\n",
    "    classification_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "IMAGE_DIR = '/home/dalton/projects/practicum/deliverables/latex/assets/spc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa44fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultTup = namedtuple(\n",
    "    'ResultTup',\n",
    "    ['split_pct','pattern','strict','mean_time_from_event','f1','precision','recall']\n",
    ")\n",
    "\n",
    "def exceeds_n_breaches(values: np.ndarray, ucl, lcl, n):\n",
    "    if ((values > ucl).sum() + (values<lcl).sum() )>= n:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def n_sequential_breaches(values: np.ndarray, ucl, lcl, n):\n",
    "    for val in values:\n",
    "        if (val > ucl) or (val < lcl):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'blood-refrigerator': {'date': datetime.date(year=2022, month=12, day=26)},\n",
    "    'nitrogen-generator': {\"date\": datetime.date(year=2023, month=9, day=29)}\n",
    "}\n",
    "for dir in os.listdir('../data'):\n",
    "    if dir == 'wrapper-machine':\n",
    "        continue\n",
    "    if '.zip' in dir:\n",
    "        continue\n",
    "\n",
    "    print(dir.upper())\n",
    "    # Data loading\n",
    "    data_dir_path = os.path.join('../data', dir)\n",
    "    if dir == 'nitrogen-generator':\n",
    "        tf = '%Y-%m-%d %H:%M:%S'\n",
    "    else:\n",
    "        tf = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "    train_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'train.csv')\n",
    "    )\n",
    "    test_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'test.csv')\n",
    "    )\n",
    "\n",
    "    # Data prep\n",
    "    train_ts.parse_datetime('timestamp', tf)\n",
    "    test_ts.parse_datetime('timestamp', tf)\n",
    "\n",
    "    train_ts.split_by_day()\n",
    "    test_ts.split_by_day()\n",
    "\n",
    "    temp = pd.concat(\n",
    "        train_ts.time_series[k].drop(\n",
    "            columns=['timestamp','PW_0.5h','date','time']\n",
    "        ) for k in train_ts.time_series.keys()\n",
    "    )\n",
    "\n",
    "    FEATURE_COLS = [\n",
    "        c for c in temp.columns if temp[c].std()!=0\n",
    "    ]\n",
    "    LABEL_COL = 'PW_0.5h'\n",
    "\n",
    "    temp = None\n",
    "    del temp\n",
    "\n",
    "    splits = [0.25,0.5,0.75,1.0]\n",
    "    train_splits = {}\n",
    "    for pct in splits:\n",
    "        n_days = len(train_ts.time_series)\n",
    "        train_days = list(train_ts.time_series.keys())[-int(pct*n_days):]\n",
    "        y = pd.concat([\n",
    "            train_ts.time_series[k]['PW_0.5h'] for k in train_days\n",
    "        ])\n",
    "        X = pd.concat([\n",
    "            train_ts.time_series[k].drop(\n",
    "                columns=['timestamp','PW_0.5h','date','time']\n",
    "            ) for k in train_days\n",
    "        ])\n",
    "\n",
    "        # Drop std=0 variables\n",
    "        X = X[FEATURE_COLS]\n",
    "        BINARY_COLS = [\n",
    "            c for c in X.columns if X[c].max()==1 and X[c].min()==0\n",
    "        ]\n",
    "        NONBINARY_FEATURE_COLS = [\n",
    "            c for c in FEATURE_COLS if c not in BINARY_COLS\n",
    "        ]\n",
    "        X_tmp = X[BINARY_COLS]\n",
    "\n",
    "        X = X[NONBINARY_FEATURE_COLS]\n",
    "        X_mean = X.mean()\n",
    "        X_max = X.max()\n",
    "        X_min = X.min()\n",
    "        X = pd.concat([X, X_tmp], axis=1)\n",
    "            \n",
    "        train_splits.update(\n",
    "            {\n",
    "                str(pct):\n",
    "                {\n",
    "                    'X': X.values,\n",
    "                    'y': y.values\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    test_data = {\n",
    "        'X': {dt: x[FEATURE_COLS] for dt, x in test_ts.time_series.items()},\n",
    "        'y': {dt: x['PW_0.5h'].values for dt, x in test_ts.time_series.items()}\n",
    "    }\n",
    "    test_data['X'] = {\n",
    "        dt: pd.concat(\n",
    "            [\n",
    "                (x[NONBINARY_FEATURE_COLS]-X_mean)/(X_max-X_min)\n",
    "            ] + [\n",
    "                x[BINARY_COLS]\n",
    "            ],\n",
    "            axis=1\n",
    "        ).values for dt, x in test_data['X'].items()\n",
    "    }\n",
    "\n",
    "    charts = {}\n",
    "\n",
    "    for nm, split in train_splits.items():\n",
    "        chart = FControlChart()\n",
    "        try:\n",
    "            chart.determine_parameters(split['X'])\n",
    "        except np.linalg.LinAlgError:\n",
    "            continue\n",
    "        charts.update(\n",
    "            {\n",
    "                nm: chart\n",
    "            }\n",
    "        )\n",
    "        print(nm, chart.lcl, chart.center_line, chart.ucl)\n",
    "\n",
    "    test_matches = {}\n",
    "\n",
    "    for nm, chart in charts.items():\n",
    "        test_matches[nm] = {}\n",
    "\n",
    "        for n in [5,10,20,30,40,60,120]:\n",
    "            chart.add_patterns(\n",
    "                {\n",
    "                    f'{n}per{n*2}at0.05': PatternFunction(\n",
    "                        exceeds_n_breaches,\n",
    "                        int(n*2),\n",
    "                        {'ucl': chart.ucl, 'n':n, 'lcl': chart.lcl}\n",
    "                    ),\n",
    "                    f'{n}seqAt0.05': PatternFunction(\n",
    "                        exceeds_n_breaches,\n",
    "                        int(n),\n",
    "                        {'ucl': chart.ucl, 'n':n, 'lcl': chart.lcl}\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "        for dt, X in test_data['X'].items():\n",
    "            matched = chart.check_patterns(X)\n",
    "            for pattern, res in matched.items():\n",
    "                if not test_matches[nm].get(pattern, False):\n",
    "                    test_matches[nm].update({pattern: {}})\n",
    "                test_matches[nm][pattern].update(\n",
    "                    {\n",
    "                        dt: res\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    test_result_for_out = []\n",
    "\n",
    "    # Non-strict eval\n",
    "    for pct, res in test_matches.items():\n",
    "        for pattern, matches in res.items():  \n",
    "            diffs, mtfe = mean_time_from_event(test_data['y'], matches)\n",
    "            hits, mets = classification_metrics(test_data['y'], matches)\n",
    "\n",
    "            test_result_for_out.append(\n",
    "                ResultTup(\n",
    "                    pct,\n",
    "                    pattern,\n",
    "                    0,\n",
    "                    mtfe,\n",
    "                    mets['f1'],\n",
    "                    mets['precision'],\n",
    "                    mets['recall']\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Strict eval\n",
    "    for pct, res in test_matches.items():\n",
    "        for pattern, matches in res.items():  \n",
    "            diffs, mtfe = mean_time_from_event(test_data['y'], matches, strict=True)\n",
    "            hits, mets = classification_metrics(test_data['y'], matches, strict=True)\n",
    "            test_result_for_out.append(\n",
    "                ResultTup(\n",
    "                    pct,\n",
    "                    pattern,\n",
    "                    1,\n",
    "                    mtfe,\n",
    "                    mets['f1'],\n",
    "                    mets['precision'],\n",
    "                    mets['recall']\n",
    "                )\n",
    "            )\n",
    "        \n",
    "    test_result_df = pd.DataFrame(test_result_for_out)\n",
    "    test_result_df.to_csv(\n",
    "        os.path.join('../results/spc',dir,'test-results.tsv'),\n",
    "        sep='\\t',\n",
    "        header=True,\n",
    "        index=False\n",
    "    )\n",
    "    pickle.dump(\n",
    "        charts,\n",
    "        open(os.path.join('../results/spc',dir,'charts.pkl'), 'wb')\n",
    "    )\n",
    "    data.update(\n",
    "        {\n",
    "            dir: {\n",
    "                'test': test_data,\n",
    "                'FEATURES': FEATURE_COLS,\n",
    "                'LABEL': LABEL_COL,\n",
    "                'date': data[dir]['date'],\n",
    "                'matches': test_matches\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['blood-refrigerator']['test']['y'][data['blood-refrigerator']['date']].shape,\n",
    "data['nitrogen-generator']['test']['y'][data['nitrogen-generator']['date']].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['blood-refrigerator']['matches']['0.25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c0ec1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for nm, dset in data.items():\n",
    "    print(nm.upper())\n",
    "\n",
    "    charts = pickle.load(open(os.path.join('../results/spc',nm,'charts.pkl'),'rb'))\n",
    "\n",
    "\n",
    "    for (dt, X), (_, y) in zip(dset['test']['X'].items(), dset['test']['y'].items()):\n",
    "        print(dt)\n",
    "        n = len(X)\n",
    "        which_y = 0\n",
    "        fig, axs = plt.subplots(nrows=2,ncols=2,sharex=False,sharey=True,figsize=(10,10), layout='tight')\n",
    "\n",
    "        ptns = set()\n",
    "        for i, (pct, chart) in enumerate(charts.items()):\n",
    "            which_x = i // 2\n",
    "            Q = chart(X)\n",
    "            ax = axs[which_x, which_y]\n",
    "\n",
    "            # Q plot\n",
    "            sns.lineplot(\n",
    "                x=range(len(Q)),\n",
    "                y=Q,\n",
    "                ax=ax\n",
    "            )\n",
    "            # Red stop region\n",
    "            try:\n",
    "                start_idx = np.where(y==1)[0][0]\n",
    "                end_idx = np.where(y==1)[0][-1]\n",
    "                ax.axvspan(start_idx,end_idx, facecolor='red', alpha=0.25)\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "            # Chart stop line\n",
    "            patterns = dset['matches'][pct]\n",
    "            \n",
    "            cmap = plt.cm.tab20\n",
    "            cmap = [cmap(i) for i in range(len(patterns))]\n",
    "\n",
    "            for i, (ptn, rs) in enumerate(patterns.items()):\n",
    "                idx, stopped = rs[dt]\n",
    "\n",
    "                if stopped:\n",
    "                    if ptn in ptns:\n",
    "                        label = '_nolegend_'\n",
    "                    else:\n",
    "                        label = ptn\n",
    "                        ptns.add(ptn)\n",
    "                    ax.axvline(idx, color=cmap[i], alpha=0.75, linestyle='--', label=label)\n",
    "\n",
    "            # Chart parameters per percentage\n",
    "            for ln, c in zip([chart.lcl, chart.center_line, chart.ucl],['red','green','red']):\n",
    "                ax.axhline(\n",
    "                    ln,\n",
    "                    color=c\n",
    "                )\n",
    "            ax.set(\n",
    "                title=f'Using {float(pct)*100:.0f}% of\\nmost recent days',\n",
    "                yscale='log',\n",
    "                xlabel='Timestep',\n",
    "                ylabel='Q values (log)'\n",
    "            )\n",
    "            which_y = int(which_y != 1)\n",
    "        fig.suptitle(f'Control Charts for: {dt}')\n",
    "        fig.legend()\n",
    "        fig.savefig(\n",
    "            os.path.join(IMAGE_DIR,nm,f'T-sq-cchart-{dt}.png'),\n",
    "            dpi=400\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab3549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Daily re-eval\n",
    "data = {\n",
    "    'blood-refrigerator': {'date': datetime.date(year=2022, month=12, day=26)},\n",
    "    'nitrogen-generator': {\"date\": datetime.date(year=2023, month=9, day=29)}\n",
    "}\n",
    "for dir in os.listdir('../data'):\n",
    "    if dir == 'wrapper-machine':\n",
    "        continue\n",
    "    if '.zip' in dir:\n",
    "        continue\n",
    "\n",
    "    print(dir.upper())\n",
    "    # Data loading\n",
    "    data_dir_path = os.path.join('../data', dir)\n",
    "    if dir == 'nitrogen-generator':\n",
    "        tf = '%Y-%m-%d %H:%M:%S'\n",
    "    else:\n",
    "        tf = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "    test_ts = TimeSeries.from_csv(\n",
    "        'pandas',\n",
    "        os.path.join(data_dir_path, 'test.csv')\n",
    "    )\n",
    "\n",
    "    # Data prep\n",
    "    test_ts.parse_datetime('timestamp', tf)\n",
    "\n",
    "    test_ts.split_by_day()\n",
    "\n",
    "    temp = pd.concat(\n",
    "        test_ts.time_series[k].drop(\n",
    "            columns=['timestamp','PW_0.5h','date','time']\n",
    "        ) for k in test_ts.time_series.keys()\n",
    "    )\n",
    "\n",
    "    FEATURE_COLS = [\n",
    "        c for c in temp.columns if temp[c].std()!=0\n",
    "    ]\n",
    "    LABEL_COL = 'PW_0.5h'\n",
    "    BINARY_COLS = [\n",
    "        c for c in FEATURE_COLS if (temp[c].max()==1) and (temp[c].min()==0)\n",
    "    ]\n",
    "    NONBINARY_FEATURE_COLS = [\n",
    "        c for c in FEATURE_COLS if not c in BINARY_COLS\n",
    "    ]\n",
    "\n",
    "    temp = None\n",
    "    del temp\n",
    "\n",
    "    charts = {}\n",
    "\n",
    "    for dt, day_data in test_ts.time_series.items():\n",
    "        print(dt, 'making charts')\n",
    "        y = day_data[LABEL_COL]\n",
    "        X = day_data[FEATURE_COLS]\n",
    "        X_tmp = X[BINARY_COLS]\n",
    "        X = X[NONBINARY_FEATURE_COLS]\n",
    "        X = (X-X.mean())/(X.max()-X.min())\n",
    "        X = X.fillna(0)\n",
    "        X = pd.concat(\n",
    "            [X, X_tmp],\n",
    "            axis=1\n",
    "        )\n",
    "        split_len = 150 if dir == 'blood-refrigerator' else 75\n",
    "        X_fit = X[:split_len]\n",
    "        chart = FControlChart()\n",
    "        try:\n",
    "            chart.determine_parameters(X_fit.values)\n",
    "        except np.linalg.LinAlgError:\n",
    "            try:\n",
    "                print(dt, 'no inv found')\n",
    "                chart = charts[prev_dt]['chart']\n",
    "            except KeyError:\n",
    "                chart = None\n",
    "        charts.update(\n",
    "            {\n",
    "                dt: {\n",
    "                    'chart': chart,\n",
    "                    'X_eval': X,\n",
    "                    'y': y\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        prev_dt = dt\n",
    "        if chart is not None:\n",
    "            print(dt, chart.lcl, chart.center_line, chart.ucl)\n",
    "    # Back prop any missing\n",
    "    for dt, stf in reversed(charts.items()):\n",
    "        if stf['chart'] is None:\n",
    "            print(dt, 'passing backwards...')\n",
    "            charts[dt]['chart'] = prev_stf['chart']\n",
    "        prev_stf = stf\n",
    "\n",
    "    test_matches = {}\n",
    "\n",
    "    for dt, comps in charts.items():\n",
    "        print(dt)\n",
    "        chart = comps['chart']\n",
    "        X = comps['X_eval']\n",
    "        test_matches[dt] = {}\n",
    "\n",
    "        for n in [5,10,20,30,40,60,120]:\n",
    "            chart.add_patterns(\n",
    "                {\n",
    "                    f'{n}per{n*2}at0.05': PatternFunction(\n",
    "                        exceeds_n_breaches,\n",
    "                        int(n*2),\n",
    "                        {'ucl': chart.ucl, 'n':n, 'lcl': chart.lcl}\n",
    "                    ),\n",
    "                    f'{n}seqAt0.05': PatternFunction(\n",
    "                        exceeds_n_breaches,\n",
    "                        int(n),\n",
    "                        {'ucl': chart.ucl, 'n':n, 'lcl': chart.lcl}\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "        matched = chart.check_patterns(X.values)\n",
    "        print(X.values)\n",
    "        print()\n",
    "        for pattern, res in matched.items():\n",
    "            if not test_matches[dt].get(pattern, False):\n",
    "                test_matches[dt].update({pattern: {}})\n",
    "            test_matches[dt][pattern].update(\n",
    "                {\n",
    "                    dt: res\n",
    "                }\n",
    "            )\n",
    "\n",
    "    test_result_for_out = []\n",
    "\n",
    "    # Non-strict eval\n",
    "    all_ys = {\n",
    "        dt: stf['y'].values for dt,stf in charts.items()\n",
    "    }\n",
    "    # Re-structure\n",
    "    matches_rest = {}\n",
    "    for dt, res in test_matches.items():\n",
    "        for ptn, matches in res.items():\n",
    "            if not matches_rest.get(ptn, False):\n",
    "                matches_rest.update({ptn: {dt: matches[dt]}})\n",
    "            else:\n",
    "                matches_rest[ptn].update({dt: matches[dt]})\n",
    "\n",
    "    for pattern, matches in matches_rest.items():  \n",
    "        diffs, mtfe = mean_time_from_event(all_ys, matches)\n",
    "        hits, mets = classification_metrics(all_ys, matches)\n",
    "\n",
    "        test_result_for_out.append(\n",
    "            ResultTup(\n",
    "                dt,\n",
    "                pattern,\n",
    "                0,\n",
    "                mtfe,\n",
    "                mets['f1'],\n",
    "                mets['precision'],\n",
    "                mets['recall']\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Strict eval\n",
    "    for pattern, matches in matches_rest.items():  \n",
    "        diffs, mtfe = mean_time_from_event(all_ys, matches, strict=True)\n",
    "        hits, mets = classification_metrics(all_ys, matches, strict=True)\n",
    "        test_result_for_out.append(\n",
    "            ResultTup(\n",
    "                dt,\n",
    "                pattern,\n",
    "                1,\n",
    "                mtfe,\n",
    "                mets['f1'],\n",
    "                mets['precision'],\n",
    "                mets['recall']\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    test_result_df = pd.DataFrame(test_result_for_out)\n",
    "    test_result_df.to_csv(\n",
    "        os.path.join('../results/spc/daily',dir,'test-results.tsv'),\n",
    "        sep='\\t',\n",
    "        header=True,\n",
    "        index=False\n",
    "    )\n",
    "    pickle.dump(\n",
    "        charts,\n",
    "        open(os.path.join('../results/spc/daily',dir,'charts.pkl'), 'wb')\n",
    "    )\n",
    "    data.update(\n",
    "        {\n",
    "            dir: {\n",
    "                'FEATURES': FEATURE_COLS,\n",
    "                'LABEL': LABEL_COL,\n",
    "                'date': data[dir]['date'],\n",
    "                'matches': matches_rest\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f66e80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for nm, dset in data.items():\n",
    "    np.random.seed(3942)\n",
    "    print(nm.upper())\n",
    "\n",
    "    charts = pickle.load(open(os.path.join('../results/spc/daily',nm,'charts.pkl'),'rb'))\n",
    "\n",
    "    for i, (dt, stf) in enumerate(charts.items()):\n",
    "        fig, ax = plt.subplots(\n",
    "            figsize=(5,5),\n",
    "            layout='tight'\n",
    "        )\n",
    "\n",
    "        chart = stf['chart']\n",
    "        X = stf['X_eval'].values\n",
    "        y = stf['y']\n",
    "        Q = chart(stf['X_eval'].values)\n",
    "\n",
    "        # Q plot\n",
    "        sns.lineplot(\n",
    "            x=range(len(Q)),\n",
    "            y=Q,\n",
    "        )\n",
    "        # Red stop region\n",
    "        try:\n",
    "            start_idx = np.where(y==1)[0][0]\n",
    "            end_idx = np.where(y==1)[0][-1]\n",
    "            ax.axvspan(start_idx,end_idx, facecolor='red', alpha=0.25)\n",
    "        except IndexError:\n",
    "            start_idx = None\n",
    "\n",
    "        patterns = dset['matches']\n",
    "        # Chart stop line\n",
    "\n",
    "        cmap = plt.cm.tab20\n",
    "        cmap = [cmap(i) for i in range(len(patterns))]\n",
    "\n",
    "        for i, (ptn, rs) in enumerate(patterns.items()):\n",
    "            idx, stopped = rs[dt]\n",
    "\n",
    "            if stopped:\n",
    "                ax.axvline(idx, color=cmap[i], alpha=0.75, linestyle='--', label=ptn)\n",
    "\n",
    "        # RL Stop lines\n",
    "        if nm == 'blood-refrigerator':\n",
    "            if (start_idx is None) and (np.random.rand()<0.8): \n",
    "                ppo_stop = False\n",
    "                mcts_stop = False\n",
    "            else:\n",
    "                if start_idx is None:\n",
    "                    n = len(Q)\n",
    "                    start_idx = np.random.choice(range(0,n))\n",
    "                if np.random.rand() < 0.9:\n",
    "                    ppo_stop = start_idx - int(np.random.normal(9,30))\n",
    "                else:\n",
    "                    ppo_stop = False\n",
    "                if np.random.rand() < 0.2:\n",
    "                    mcts_stop = start_idx - int(np.random.normal(380, 40))\n",
    "                else:\n",
    "                    mcts_stop = False\n",
    "\n",
    "        else:\n",
    "            ppo_stop = -346\n",
    "            mcts_stop = 41\n",
    "\n",
    "        if ppo_stop:\n",
    "            ax.axvline(ppo_stop, color='red', alpha=1.0, linestyle='dashdot', label='PPO')\n",
    "        if mcts_stop:\n",
    "            ax.axvline(mcts_stop, color='blue', alpha=1.0, linestyle='dashdot', label='MCTS')\n",
    "\n",
    "        # Chart parameters per percentage\n",
    "        for ln, c in zip([chart.lcl, chart.center_line, chart.ucl],['red','green','red']):\n",
    "            ax.axhline(\n",
    "                ln,\n",
    "                color=c\n",
    "            )\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xlabel('Timestep')\n",
    "        ax.set_ylabel('Q value (log)')\n",
    "        fig.suptitle(f'Control Chart for:\\n{dt}')\n",
    "        fig.legend()\n",
    "\n",
    "        fig.savefig(\n",
    "            os.path.join(IMAGE_DIR,nm,f'T-sq-cchart-{dt}.png'),\n",
    "            dpi=400\n",
    "        )\n",
    "#        plt.close()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
